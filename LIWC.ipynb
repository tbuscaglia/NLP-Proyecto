{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNMmXMEkeSptd/20XgUiWZy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KxNXSiUZGo3c"},"outputs":[],"source":["#Spanish\n","!gdown 16ozJQD5udoyWo132lawxIr_BR5vekEHZ\n","!gdown 1_ys9r6qAOEjz0w4SAY4--jAnGvP6XQpe\n","#English\n","!gdown 1Bw1w9HwJb4ONfz_-ATiaL-F4QaI2fl09\n","!gdown 12phHiLvQK7uRPgdeI5NbVwAdL_sjF1OE"]},{"cell_type":"code","source":["from LIWC_spanish import liwc as liwc_es\n","from LIWC import liwc as liwc_en"],"metadata":{"id":"Y2nf1ju8GrRi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector_list_en = {}\n","with open('english_songs.csv', 'r', encoding='utf-8') as csv_file:\n","    csv_reader = csv.reader(csv_file)\n","    next(csv_reader)\n","    for row in csv_reader:\n","        artist = row[0]\n","        song = row[1]\n","        lyrics = row[2]\n","        L2 = liwc_en().getLIWCCount(lyrics)\n","        HEADERS = list(L2.keys())\n","        HEADERS.sort()\n","        vector = []\n","        for h in HEADERS:\n","          if h != 'WC':\n","            vector.append(L2[h]/L2['WC'])\n","          else:\n","            vector.append(L2[h])\n","        vector_list_en[(artist,song)]=vector"],"metadata":{"id":"vEB_QfCtGs10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["C = []\n","for v in vector_list_en:\n","  C.append(vector_list_en[v])"],"metadata":{"id":"dqPZ8eAnGud1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","C = np.array(C)\n","D = np.transpose(C)"],"metadata":{"id":"KdxZW6sIGv-J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rep_feats = {}\n","for i in range(0,len(D)):\n","  if HEADERS[i] != 'WC':\n","    rep_feats[HEADERS[i]]=np.std(D[i])\n","values = list(rep_feats.values())\n","M = np.mean(values)\n","STD = np.std(values)\n","\n","sorted(rep_feats.items(), key=lambda item: item[1])"],"metadata":{"id":"gZ1GS4IxGxjw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector_list_es = {}\n","with open('spanish_songs.csv', 'r', encoding='utf-8') as csv_file:\n","    csv_reader = csv.reader(csv_file)\n","    next(csv_reader)\n","    for row in csv_reader:\n","        artist = row[0]\n","        song = row[1]\n","        lyrics = row[2].lower()\n","        L2 = liwc_es().getLIWCCount(lyrics)\n","        HEADERS_ES = list(L2.keys())\n","        HEADERS_ES.sort()\n","        vector = []\n","        for h in HEADERS_ES:\n","          if h != 'WC':\n","            vector.append(L2[h]/L2['WC'])\n","          else:\n","            vector.append(L2[h])\n","        vector_list_es[(artist,song)]=vector"],"metadata":{"id":"lKwe8qn1G1X9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["A = []\n","for v in vector_list_es:\n","  A.append(vector_list_es[v])"],"metadata":{"id":"A2vpRAvEG6ru"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","A = np.array(A)\n","B = np.transpose(A)"],"metadata":{"id":"6FcoCj80G8kN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rep_feats = {}\n","for i in range(0,len(B)):\n","  if HEADERS_ES[i] != 'WC':\n","    rep_feats[HEADERS_ES[i]]=np.std(B[i])\n","values = list(rep_feats.values())\n","M = np.mean(values)\n","STD = np.std(values)\n","\n","sorted(rep_feats.items(), key=lambda item: item[1])"],"metadata":{"id":"HcN6jve4G-Rv"},"execution_count":null,"outputs":[]}]}